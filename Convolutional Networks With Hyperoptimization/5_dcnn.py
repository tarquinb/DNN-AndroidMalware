from hyperopt import Trials, STATUS_OK, tpe
from hyperas import optim
from hyperas.distributions import choice, uniform, conditional

from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.callbacks import TensorBoard
from keras.utils import np_utils

import numpy as np
import pandas as pd
import os


def data():
    '''
    Read pandas dataframe from pickle and prepare for keras input.
    :param datafile: Pickle containing pandas dataframe with training data
    :return: numpy array containing document vectors and list containing labels
             Label 0 - benign; 1 - Malware
    '''
    NUM_CLASS = 2
    FINDIR = os.path.join('DATA/FIN')
    # MODELPATH = os.path.join('MODELS')
    TRAINFILE = 'df_train.pickle'
    # TRAINVECS = d2v.load(MODELPATH +
    #                      '/d2v_300_train_data_BM.model')
    TESTFILE = '/df_test.pickle'
    train_data = []
    train_labels = []
    test_data = []
    test_labels = []

    train = pd.read_pickle(FINDIR + '/' + TRAINFILE,
                           compression='gzip')
    for i in list(train.index):
        doc = train.loc[i]['docvec']
        train_data.append(list(doc))
        if train.loc[i]['label'] == 'BENIGN':
            train_labels.append(0)
        else:
            train_labels.append(1)
    train_data = np.array(train_data)

    test = pd.read_pickle(FINDIR + '/' + TESTFILE,
                          compression='gzip')
    for i in list(test.index):
        doc = test.loc[i]['docvec']
        test_data.append(list(doc))
        if test.loc[i]['label'] == 'BENIGN':
            test_labels.append(0)
        else:
            test_labels.append(1)
    test_data = np.array(test_data)
    print(np.shape(train_data))
    train_data = train_data[:, np.newaxis, :, :]
    train_data = np.interp(train_data, (train_data.min(), train_data.max()),
                           (-1, +1))
    test_data = test_data[:, np.newaxis, :, :]
    test_data = np.interp(test_data, (test_data.min(), test_data.max()),
                          (-1, +1))

    train_labels = np_utils.to_categorical(train_labels, NUM_CLASS)
    test_labels = np_utils.to_categorical(test_labels, NUM_CLASS)

    return train_data, train_labels, test_data, test_labels


def convnet(train_data, train_labels, test_data, test_labels):
    '''
    Convolutional Neural Network defined.
    '''
    SEED = 123
    np.random.seed(SEED)
    NB_CLASSES = 2
    DOC_ROWS = 1
    DOC_COLS = 300
    INPUT_SHAPE = (1, DOC_ROWS, DOC_COLS)

    model = Sequential()

    model.add(Dropout({{uniform(0, 1)}}, input_shape=INPUT_SHAPE))

    model.add(Conv2D({{choice([5, 10, 15, 20, 50, 100])}},
                     kernel_size={{choice([5, 10, 20])}},
                     padding='same',
                     kernel_initializer={{choice(['TruncatedNormal',
                                          'random_normal'])}}))
    model.add(Activation({{choice(["tanh", "relu"])}}))
    model.add(Dropout({{uniform(0, 1)}}))

    if conditional({{choice(['yes', 'no'])}}) == 'yes':
        model.add(MaxPooling2D(pool_size=(1, 1),
                               strides=None))
    model.add(Conv2D({{choice([5, 10, 15, 20, 50, 100])}},
                     kernel_size={{choice([5, 10, 20])}},
                     padding='same',
                     kernel_initializer={{choice(['TruncatedNormal',
                                          'random_normal'])}}))

    model.add(Activation({{choice(["tanh", "relu"])}}))
    model.add(Dropout({{uniform(0, 1)}}))

    if conditional({{choice(['yes', 'no'])}}) == 'yes':
        model.add(MaxPooling2D(pool_size=(1, 1),
                               strides=None))

    if conditional({{choice(['yes', 'no'])}}) == 'yes':
        model.add(Conv2D({{choice([5, 10, 15, 20, 50, 100])}},
                         kernel_size={{choice([5, 10, 20])}},
                         padding='same',
                         kernel_initializer={{choice(['TruncatedNormal',
                                              'random_normal'])}}))
        model.add(Activation({{choice(["tanh", "relu"])}}))
        model.add(Dropout({{uniform(0, 1)}}))

    if conditional({{choice(['yes', 'no'])}}) == 'yes':
        model.add(Conv2D({{choice([5, 10, 15, 20, 50, 100])}},
                         kernel_size={{choice([5, 10, 20])}},
                         padding='same',
                         kernel_initializer={{choice(['TruncatedNormal',
                                              'random_normal'])}}))
        model.add(Activation({{choice(["tanh", "relu"])}}))
        model.add(Dropout({{uniform(0, 1)}}))

    model.add(Flatten())

    model.add(Dense({{choice([250, 500])}}))
    model.add(Activation({{choice(["tanh", "relu"])}}))
    model.add(Dropout({{uniform(0, 1)}}))

    if conditional({{choice(['yes', 'no'])}}) == 'yes':
        model.add(Dense({{choice([250, 500, 750])}}))
        model.add(Activation({{choice(["tanh", "relu"])}}))
        model.add(Dropout({{uniform(0, 1)}}))

    model.add(Dense(NB_CLASSES))
    model.add(Activation({{choice(["softmax", "sigmoid", "hard_sigmoid"])}}))

    model.compile(loss={{choice(['categorical_crossentropy',
                         'binary_crossentropy'])}}, metrics=['accuracy'],
                  optimizer={{choice(['rmsprop', 'adam', 'sgd', 'nadam',
                                     'adamax'])}})

    history = model.fit(train_data, train_labels,
                        batch_size={{choice([32, 64, 128, 256, 512])}},
                        epochs={{choice([10, 20, 50, 100])}}, verbose=1,
                        validation_split={{uniform(0, 1)}},
                        callbacks=[TensorBoard(log_dir=os.path.join('LOGS/dcnn_d2v300_BM'),
                                               histogram_freq=0,
                                               write_graph=True,
                                               write_grads=False,
                                               write_images=False,
                                               embeddings_freq=0,
                                               embeddings_layer_names=None,
                                               embeddings_metadata=None)])

    score, acc = model.evaluate(test_data, test_labels, verbose=1)

    print('History')
    print(history.history.keys())

    print('Test Score: {}'.format(score))
    print('Test Accuracy: {}'.format(acc))

    out = {'loss': -acc, 'status': STATUS_OK, 'model': model}

    return out


def main():
    best_run, best_model = optim.minimize(model=convnet, data=data,
                                          algo=tpe.suggest, max_evals=50,
                                          trials=Trials())
    train_data, train_labels, test_data, test_labels = data()
    print("Evalutation of best performing model:")
    print(best_model.evaluate(test_data, test_labels))
    print("Best performing model chosen hyper-parameters:")
    print(best_run)

    best_model.save(os.path.join('MODELS') +
                    '/dcnn_red_bestbase_300dv.h5')


if __name__ == '__main__':
    main()
